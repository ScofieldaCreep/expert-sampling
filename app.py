import io
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
import streamlit as st
from datetime import datetime
from streamlit.components.v1 import html as st_html


# --------------------------- é¡µé¢ä¸å¸¸é‡ ---------------------------
st.set_page_config(page_title="ä¸“å®¶æŠ½æ ·åŠ©æ‰‹", page_icon="ğŸ¯", layout="wide")

REQUIRED_FIELDS_CN = {
    "name": "å§“å",
    "major": "ä¸“ä¸š",
    "phone": "æ‰‹æœºå·",
    "title": "èŒç§°",
    "email": "é‚®ç®±",
}

POSSIBLE_COLUMN_ALIASES: Dict[str, List[str]] = {
    "name": ["å§“å", "åå­—", "Name", "å§“å/Name", "å‘˜å·¥å§“å"],
    "major": ["ä¸“ä¸š", "ä¸“ä¸šæ–¹å‘", "Major", "å­¦ç§‘", "é¢†åŸŸ"],
    "phone": ["æ‰‹æœºå·", "æ‰‹æœº", "ç”µè¯", "è”ç³»ç”µè¯", "Phone", "Mobile", "æ‰‹æœºå·ç ", "è”ç³»æ‰‹æœº"],
    "title": ["èŒç§°", "æŠ€æœ¯èŒç§°", "Title", "å²—ä½", "å²—ä½/èŒç§°"],
    "email": ["é‚®ç®±", "ç”µå­é‚®ç®±", "Email", "E-mail"],
}

# å¯é€‰å­—æ®µï¼Œç”¨äºä»¿åˆ¶ç•Œé¢æ›´å¤šç­›é€‰/å±•ç¤º
OPTIONAL_ALIASES: Dict[str, List[str]] = {
    "gender": ["æ€§åˆ«", "Gender"],
    "birth": ["å‡ºç”Ÿå¹´æœˆ", "å‡ºç”Ÿæ—¥æœŸ", "å‡ºç”Ÿ", "ç”Ÿæ—¥"],
    "idcard": ["èº«ä»½è¯å·", "èº«ä»½è¯å·ç ", "è¯ä»¶å·ç "],
    "org": ["ä¾›èŒå•ä½", "å•ä½", "å·¥ä½œå•ä½", "æ‰€åœ¨å•ä½"],
    "position": ["èŒåŠ¡", "å²—ä½", "èŒä½"],
    "degree": ["å­¦å†", "æœ€é«˜å­¦å†"],
    # åˆ é™¤æ³¨å†Œèµ„æ ¼ç­›é€‰ï¼šä¸å†åœ¨UIä¸­ä½¿ç”¨
    # "qualification": ["æ³¨å†Œèµ„æ ¼", "èµ„æ ¼", "æ³¨å†Œè¯ä¹¦"],
    "contact": ["è”ç³»æ–¹å¼", "è”ç³»ç”µè¯", "è”ç³»æ‰‹æœº", "æ‰‹æœºå·ç ", "æ‰‹æœºå·", "ç”µè¯"],
    "contact_result": ["è”ç³»ç»“æœ", "å›è®¿ç»“æœ"],
    "reg_org": ["æ³¨å†Œå•ä½", "æ³¨å†Œå•ä½åç§°", "æ³¨å†Œæœºæ„", "æ³¨å†Œå•ä½/æœºæ„"],
}

SUPPORTED_EXTENSIONS = [".xlsx", ".xls", ".csv"]


# --------------------------- å·¥å…·å‡½æ•° ---------------------------
@st.cache_data(show_spinner=False)
def load_dataframe(file_bytes: bytes, filename: str) -> pd.DataFrame:
    filename_lower = filename.lower()
    if filename_lower.endswith(".csv"):
        # è‡ªåŠ¨å°è¯•å¸¸è§ç¼–ç 
        for enc in ["utf-8", "gbk", "gb2312", "utf-8-sig"]:
            try:
                return pd.read_csv(io.BytesIO(file_bytes), encoding=enc)
            except Exception:
                continue
        return pd.read_csv(io.BytesIO(file_bytes))
    elif filename_lower.endswith(".xls"):
        return pd.read_excel(io.BytesIO(file_bytes), engine="xlrd")
    else:
        return pd.read_excel(io.BytesIO(file_bytes), engine="openpyxl")


def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    new_df = df.copy()
    new_df.columns = [str(c).strip() for c in new_df.columns]
    return new_df


def _is_empty_value(v: object) -> bool:
    s = str(v).strip()
    return s == "" or s.lower() in {"nan", "none", "null"}


def auto_locate_header_by_keyword(df: pd.DataFrame) -> pd.DataFrame:
    """æ ¹æ®åŒ…å«â€œåºå·â€ç­‰å…³é”®è¯çš„è¡Œè‡ªåŠ¨å®šä½è¡¨å¤´ã€‚
    ç­–ç•¥ï¼šè¡Œä¸­åŒ…å«â€œåºå·â€ï¼Œä¸”ä¸å¸¸è§è¡¨å¤´å…³é”®è¯äº¤é›†>=3ï¼Œåˆ™è¯¥è¡Œä¸ºè¡¨å¤´ï¼›
    ä»¥è¯¥è¡Œä¹‹ä¸‹ä¸€è¡Œä¸ºæ•°æ®å¼€å§‹ï¼›å°†è¯¥è¡Œèµ‹ä¸ºåˆ—åã€‚
    """
    if df.empty:
        return df
    s = df.astype(str).applymap(lambda x: str(x).strip())
    header_keywords = {"åºå·", "å§“å", "æ€§åˆ«", "å‡ºç”Ÿå¹´æœˆ", "èº«ä»½è¯å·", "ä¸“ä¸š", "æ‰‹æœºå·ç ", "æ‰‹æœºå·", "ä¾›èŒå•ä½", "å•ä½", "èŒç§°", "èŒåŠ¡", "ç”µå­é‚®ç®±", "é‚®ç®±", "å¤‡æ³¨"}
    header_row_idx: Optional[int] = None
    for i, row in s.iterrows():
        vals = [v for v in row.tolist() if not _is_empty_value(v)]
        if not vals:
            continue
        if "åºå·" in vals:
            if len(set(vals) & header_keywords) >= 3:
                header_row_idx = i
                break
    if header_row_idx is None:
        return df
    columns = s.iloc[header_row_idx].tolist()
    columns = [c if not _is_empty_value(c) else f"åˆ—{j+1}" for j, c in enumerate(columns)]
    body = df.iloc[header_row_idx + 1 :].copy()
    body.columns = columns
    return normalize_columns(body)


def drop_group_header_rows(df: pd.DataFrame) -> pd.DataFrame:
    """åˆ é™¤ä»…åŒ…å«ä¸€ä¸ªéç©ºæ–‡æœ¬ï¼Œä¸”è¯¥æ–‡æœ¬ç–‘ä¼¼åˆ†ç»„æ ‡é¢˜çš„è¡Œï¼Œä¾‹å¦‚â€œä¿¡æ¯åŒ–ä¸“ä¸šâ€ã€‚
    åˆ¤å®šè§„åˆ™ï¼š
    - è¡Œå†…éç©ºå•å…ƒæ ¼æ•°é‡<=2ï¼Œä¸”
    - å­˜åœ¨éç©ºå€¼æ»¡è¶³ï¼šç­‰äºâ€œä¿¡æ¯åŒ–ä¸“ä¸šâ€æˆ–ä»¥â€œä¸“ä¸šâ€ç»“å°¾æˆ–ä»¥â€œç±»åˆ«â€ç»“å°¾
    """
    if df.empty:
        return df
    s = df.astype(str).applymap(lambda x: str(x).strip())
    mask_drop = []
    for _, row in s.iterrows():
        vals = [v for v in row.tolist() if not _is_empty_value(v)]
        if len(vals) <= 2:
            candidate = "".join(vals)
            candidate = candidate.replace(" ", "")
            if candidate in {"ä¿¡æ¯åŒ–ä¸“ä¸š"} or candidate.endswith("ä¸“ä¸š") or candidate.endswith("ç±»åˆ«"):
                mask_drop.append(True)
                continue
        mask_drop.append(False)
    return df.loc[[not x for x in mask_drop]]


def drop_embedded_header_rows(df: pd.DataFrame) -> pd.DataFrame:
    """åˆ é™¤è¡¨å†…é‡å¤çš„è¡¨å¤´è¡Œï¼ˆä¾‹å¦‚åˆ†é¡µååˆå‡ºç°ä¸€æ¬¡â€˜å§“å/ä¸“ä¸š/èŒç§°/...â€™ï¼‰ã€‚
    è§„åˆ™ï¼šå¦‚æœæœ¬è¡Œå«æœ‰è‡³å°‘3ä¸ªå­—æ®µåå…³é”®å­—ï¼Œåˆ™åˆ¤å®šä¸ºè¡¨å¤´è¡Œã€‚
    """
    if df.empty:
        return df
    header_keywords = set(REQUIRED_FIELDS_CN.values()) | {"æ€§åˆ«", "å‡ºç”Ÿå¹´æœˆ", "èº«ä»½è¯å·", "å•ä½", "ä¾›èŒå•ä½", "èŒåŠ¡", "ç”µå­é‚®ç®±", "å¤‡æ³¨"}
    s = df.astype(str).applymap(lambda x: str(x).strip())
    keep_flags: List[bool] = []
    for _, row in s.iterrows():
        row_set = set(v for v in row.tolist() if not _is_empty_value(v))
        intersect_cnt = len(row_set & header_keywords)
        keep_flags.append(intersect_cnt < 3)
    return df.loc[keep_flags]


def _find_first_match(df: pd.DataFrame, aliases: List[str]) -> Optional[str]:
    cols = list(df.columns)
    cols_lc = {c: str(c).lower() for c in cols}
    for a in aliases:
        # ç²¾ç¡®
        for c in cols:
            if str(c).strip() == a:
                return c
        # æ¨¡ç³ŠåŒ…å«
        a_lc = a.lower()
        for c, c_lc in cols_lc.items():
            if a_lc in c_lc:
                return c
    return None


def guess_mapping(df: pd.DataFrame) -> Dict[str, Optional[str]]:
    mapping: Dict[str, Optional[str]] = {k: None for k in REQUIRED_FIELDS_CN.keys()}

    for field, aliases in POSSIBLE_COLUMN_ALIASES.items():
        col = _find_first_match(df, aliases)
        if col is not None:
            mapping[field] = col
    return mapping


def build_mapped_df(df: pd.DataFrame, mapping: Dict[str, Optional[str]]) -> Tuple[pd.DataFrame, List[str]]:
    errors: List[str] = []
    selected_cols = {}
    for key, cn in REQUIRED_FIELDS_CN.items():
        col = mapping.get(key)
        if col is None:
            errors.append(f"æœªé€‰æ‹©å­—æ®µï¼š{cn}")
        else:
            selected_cols[cn] = df[col]
    if errors:
        return pd.DataFrame(), errors

    result = pd.DataFrame(selected_cols)

    # è½»åº¦æ¸…æ´—
    for c in result.columns:
        result[c] = result[c].astype(str).str.strip().replace({"nan": "", "None": "", "null": "", "NaN": ""})

    # æ‰‹æœºå·ä»…ä¿ç•™æ•°å­—
    result[REQUIRED_FIELDS_CN["phone"]] = (
        result[REQUIRED_FIELDS_CN["phone"]]
        .str.replace(r"[^0-9]", "", regex=True)
        .str.slice(0, 20)
    )

    # åˆ é™¤ç–‘ä¼¼æ ‡é¢˜/åˆ†éš”è¡Œï¼ˆæ˜ å°„åå†å…œåº•ä¸€æ¬¡ï¼‰
    name_cn = REQUIRED_FIELDS_CN["name"]
    major_cn = REQUIRED_FIELDS_CN["major"]
    title_cn = REQUIRED_FIELDS_CN["title"]
    mask = ~(
        (result[name_cn].eq("") & (result[[major_cn, title_cn]].replace("", pd.NA).notna().sum(axis=1) <= 1))
        | (result[name_cn].isin(["å§“å", "ä¿¡æ¯åŒ–ä¸“ä¸š"]))
        | (result[major_cn].isin(["ä¿¡æ¯åŒ–ä¸“ä¸š"]))
    )
    result = result.loc[mask]

    return result, []


def describe_dataframe(df: pd.DataFrame, mapped_df: Optional[pd.DataFrame] = None) -> Dict[str, object]:
    summary = {
        "è¡Œæ•°": int(df.shape[0]),
        "åˆ—æ•°": int(df.shape[1]),
        "åˆ—å": list(map(str, df.columns)),
    }
    if mapped_df is not None and not mapped_df.empty:
        major = REQUIRED_FIELDS_CN["major"]
        title = REQUIRED_FIELDS_CN["title"]
        summary.update(
            {
                f"å”¯ä¸€{major}æ•°": int(mapped_df[major].replace("", pd.NA).nunique(dropna=True)),
                f"å”¯ä¸€{title}æ•°": int(mapped_df[title].replace("", pd.NA).nunique(dropna=True)),
                "ç¼ºå¤±ç»Ÿè®¡": mapped_df.replace("", pd.NA).isna().sum().to_dict(),
            }
        )
    return summary


def compute_sample_size(total: int, mode: str, count: int, percent: float) -> int:
    if total <= 0:
        return 0
    if mode == "æŒ‰æ•°é‡":
        return int(max(0, min(total, count)))
    # æŒ‰ç™¾åˆ†æ¯”
    n = int(np.floor(total * (percent / 100.0)))
    return max(1 if total > 0 else 0, min(total, n))


def sample_rows(df: pd.DataFrame, sample_size: int, seed: Optional[int]) -> pd.DataFrame:
    if sample_size <= 0 or df.empty:
        return df.iloc[0:0]
    rng = np.random.default_rng(None if seed in (None, "") else int(seed))
    idx = rng.choice(df.index.values, size=sample_size, replace=False)
    return df.loc[idx]


def to_excel_bytes(df: pd.DataFrame) -> bytes:
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as writer:
        df.to_excel(writer, index=False)
    buf.seek(0)
    return buf.read()


def detect_optional_columns(df: pd.DataFrame) -> Dict[str, Optional[str]]:
    found: Dict[str, Optional[str]] = {}
    for k, aliases in OPTIONAL_ALIASES.items():
        found[k] = _find_first_match(df, aliases)
    return found


def compute_age_series(birth_series: pd.Series) -> pd.Series:
    dt = pd.to_datetime(birth_series, errors="coerce")
    today = pd.Timestamp.today().normalize()
    age = (today - dt).dt.days // 365
    return age


# --------------------------- åº”ç”¨ä¸»ä½“ ---------------------------
def main() -> None:
    st.title("ğŸ¯ ä¸“å®¶æŠ½æ ·åŠ©æ‰‹")
    st.caption("ä¸Šä¼ ä¸“å®¶åº“ï¼ˆExcel/CSVï¼‰ï¼Œè‡ªåŠ¨å®šä½è¡¨å¤´ â†’ æ¸…æ´— â†’ æ˜ å°„ â†’ ç­›é€‰/æŠ½æ · â†’ å¯¼å‡º")

    uploaded = st.file_uploader(
        label="ä¸Šä¼ æ–‡ä»¶ (æ”¯æŒ .xlsx/.xls/.csv)",
        type=["xlsx", "xls", "csv"],
        accept_multiple_files=False,
    )

    if not uploaded:
        st.info("è¯·å…ˆä¸Šä¼ æ–‡ä»¶ã€‚æ”¯æŒ Excel æˆ– CSVã€‚")
        st.stop()

    try:
        raw_df = load_dataframe(uploaded.getvalue(), uploaded.name)
    except Exception as e:
        st.error(f"è¯»å–æ–‡ä»¶å¤±è´¥ï¼š{e}")
        st.stop()

    # è‡ªåŠ¨å®šä½è¡¨å¤´è¡Œï¼ˆåŸºäºâ€œåºå·â€ç­‰å…³é”®å­—ï¼‰
    df = auto_locate_header_by_keyword(raw_df)
    # è§„èŒƒåˆ—å + æ¸…æ´—æ‚é¡¹è¡Œ
    df = normalize_columns(df)
    df = drop_group_header_rows(df)
    df = drop_embedded_header_rows(df)

    st.subheader("æ•°æ®é¢„è§ˆï¼ˆè‡ªåŠ¨å®šä½è¡¨å¤´ + æ¸…æ´—åï¼‰")
    st.dataframe(df.head(50), use_container_width=True)

    # å­—æ®µæ˜ å°„ï¼ˆå¿…å¡«ï¼‰
    st.subheader("å­—æ®µæ˜ å°„")
    default_mapping = guess_mapping(df)

    mapping: Dict[str, Optional[str]] = {}
    cols = st.columns(5)
    for i, (key, cn) in enumerate(REQUIRED_FIELDS_CN.items()):
        with cols[i % 5]:
            mapping[key] = st.selectbox(
                label=f"{cn} å­—æ®µ",
                options=[None] + list(df.columns),
                index=(
                    [None] + list(df.columns)
                ).index(default_mapping.get(key)) if default_mapping.get(key) in df.columns else 0,
                format_func=lambda x: "æœªé€‰æ‹©" if x is None else str(x),
            )

    mapped_df, errors = build_mapped_df(df, mapping)
    if errors:
        st.warning("; ".join(errors))
        st.stop()

    optional_cols = detect_optional_columns(df)

    # æ¦‚è¦ä¿¡æ¯
    with st.expander("æ¦‚è¦ä¿¡æ¯", expanded=False):
        summary = describe_dataframe(df, mapped_df)
        st.json(summary, expanded=False)

    # ä¸¤ç§æ¨¡å¼ï¼šç®€æ´æ¨¡å¼ã€å®Œæ•´æ¨¡å¼(1:1)
    tab_simple, tab_clone = st.tabs(["ç®€æ´æ¨¡å¼", "å®Œæ•´æ¨¡å¼(1:1)"])

    # ---------- ç®€æ´æ¨¡å¼ï¼ˆåŸæœ‰ï¼‰ ----------
    with tab_simple:
        st.subheader("ç­›é€‰")
        col_left, col_right = st.columns(2)
        major_cn = REQUIRED_FIELDS_CN["major"]
        title_cn = REQUIRED_FIELDS_CN["title"]

        with col_left:
            majors = sorted([v for v in mapped_df[major_cn].dropna().unique() if str(v).strip() != ""])
            selected_majors = st.multiselect("æŒ‰ä¸“ä¸šç­›é€‰ï¼ˆå¯å¤šé€‰ï¼Œç•™ç©ºä¸ºå…¨éƒ¨ï¼‰", majors)
        with col_right:
            titles = sorted([v for v in mapped_df[title_cn].dropna().unique() if str(v).strip() != ""])
            selected_titles = st.multiselect("æŒ‰èŒç§°ç­›é€‰ï¼ˆå¯å¤šé€‰ï¼Œç•™ç©ºä¸ºå…¨éƒ¨ï¼‰", titles)

        filtered_df = mapped_df.copy()
        if selected_majors:
            filtered_df = filtered_df[filtered_df[major_cn].isin(selected_majors)]
        if selected_titles:
            filtered_df = filtered_df[filtered_df[title_cn].isin(selected_titles)]

        st.caption(f"ç­›é€‰åå…±æœ‰ {filtered_df.shape[0]} æ¡è®°å½•ã€‚")

        st.subheader("éšæœºæŠ½æ ·")
        mode = st.radio("æŠ½æ ·æ–¹å¼", options=["æŒ‰æ•°é‡", "æŒ‰ç™¾åˆ†æ¯”"], horizontal=True, key="simple_mode")
        col1, col2, col3 = st.columns(3)
        with col1:
            seed = st.text_input("éšæœºç§å­ï¼ˆå¯é€‰ï¼Œç•™ç©ºåˆ™æ¯æ¬¡ä¸åŒï¼‰", value="")
        with col2:
            count = st.number_input("æŠ½å–æ•°é‡", min_value=0, value=10, step=1)
        with col3:
            percent = st.slider("æŠ½å–ç™¾åˆ†æ¯”", min_value=1, max_value=100, value=20, step=1)

        sample_size = compute_sample_size(
            total=filtered_df.shape[0], mode=mode, count=int(count), percent=float(percent)
        )
        st.caption(f"å°†æŠ½å– {sample_size} æ¡è®°å½•ã€‚")

        if st.button("å¼€å§‹æŠ½æ ·", type="primary", key="simple_do_sample"):
            sampled = sample_rows(filtered_df, sample_size, seed if seed != "" else None)
            st.success(f"æŠ½æ ·å®Œæˆï¼Œå…± {sampled.shape[0]} æ¡ã€‚")
            st.dataframe(sampled, use_container_width=True)

            # ä¸‹è½½
            csv_bytes = sampled.to_csv(index=False).encode("utf-8-sig")
            excel_bytes = to_excel_bytes(sampled)
            dl_col1, dl_col2 = st.columns(2)
            with dl_col1:
                st.download_button(
                    label="ä¸‹è½½ CSV",
                    data=csv_bytes,
                    file_name="æŠ½æ ·åå•.csv",
                    mime="text/csv",
                )
            with dl_col2:
                st.download_button(
                    label="ä¸‹è½½ Excel",
                    data=excel_bytes,
                    file_name="æŠ½æ ·åå•.xlsx",
                    mime=(
                        "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    ),
                )

    # ---------- ä»¿åˆ¶æ¨¡å¼(1:1) ----------
    with tab_clone:
        st.subheader("é¡¹ç›®ä¿¡æ¯")
        st.caption("æ˜Ÿå·ä¸ºå¿…å¡«é¡¹ã€‚ä»…ç”¨äºè®°å½•æ˜¾ç¤ºï¼Œä¸å½±å“æŠ½æ ·é€»è¾‘ã€‚")
        col_a, col_b, col_c, col_d = st.columns([1.2, 1.2, 1.2, 1])
        with col_a:
            proj_name = st.text_input("é¡¹ç›®åç§°", value="", placeholder="ä¾‹å¦‚ï¼šXXé¡¹ç›®é‡‡è´­")
        with col_b:
            owner_name = st.text_input("*æ‹›æ ‡äººåç§°", value="", placeholder="ä¾‹å¦‚ï¼šXXå•ä½")
        with col_c:
            bid_no = st.text_input("*æ‹›æ ‡ç¼–å·", value="", placeholder="ä¾‹å¦‚ï¼šSD-2025-001")
        with col_d:
            draw_time = st.text_input("*æŠ½å–æ—¶é—´", value=datetime.now().strftime("%Y-%m-%d %H:%M:%S"))

        st.subheader("æŠ½å–æ¡ä»¶")
        c1, c2, c3, c4 = st.columns(4)
        major_cn = REQUIRED_FIELDS_CN["major"]
        title_cn = REQUIRED_FIELDS_CN["title"]

        with c1:
            major_opts = sorted([v for v in df[major_cn].dropna().unique() if str(v).strip() != ""]) if major_cn in df.columns else []
            major_sel = st.multiselect("ä¸“ä¸š", major_opts, key="clone_major")
        with c2:
            title_opts = sorted([v for v in df[title_cn].dropna().unique() if str(v).strip() != ""]) if title_cn in df.columns else []
            title_sel = st.multiselect("èŒç§°", title_opts, key="clone_title")
        with c3:
            gender_col = optional_cols.get("gender")
            gender_opts = sorted([v for v in df[gender_col].dropna().unique() if str(v).strip() != ""]) if gender_col else []
            gender_sel = st.selectbox("æ€§åˆ«", ["å…¨éƒ¨"] + gender_opts if gender_opts else ["å…¨éƒ¨"], index=0)
        with c4:
            birth_col = optional_cols.get("birth")
            if birth_col:
                ages = compute_age_series(df[birth_col])
                min_age = int(ages.min()) if ages.notna().any() else 18
                max_age = int(ages.max()) if ages.notna().any() else 80
                age_range = st.slider("å¹´é¾„", min_value=max(16, min_age), max_value=min(100, max_age), value=(max(18, min_age), min(65, max_age)))
            else:
                st.write("å¹´é¾„ï¼šæ— å‡ºç”Ÿå¹´æœˆï¼Œæ— æ³•ç­›é€‰")
                age_range = None

        c5, c6 = st.columns(2)
        with c5:
            degree_col = optional_cols.get("degree")
            degree_opts = sorted([v for v in df[degree_col].dropna().unique() if str(v).strip() != ""]) if degree_col else []
            degree_sel = st.selectbox("å­¦å†", ["å…¨éƒ¨"] + degree_opts if degree_opts else ["å…¨éƒ¨"], index=0)
        with c6:
            num_people = st.number_input("äººæ•°", min_value=0, value=10, step=1, help="è¾“å…¥éœ€è¦æŠ½å–çš„äººæ•°")

        st.subheader("å›é¿ï¼ˆå¤šé€‰å‰”é™¤ï¼‰")
        org_col = optional_cols.get("org")
        reg_org_col = optional_cols.get("reg_org")
        r1, r2 = st.columns(2)
        with r1:
            avoid_orgs = st.multiselect(
                "å›é¿å·¥ä½œå•ä½",
                sorted([v for v in df[org_col].dropna().unique() if str(v).strip() != ""]) if org_col else [],
                help="é€‰æ‹©è¿™äº›å•ä½çš„ä¸“å®¶å°†è¢«å‰”é™¤")
        with r2:
            avoid_reg_orgs = st.multiselect(
                "å›é¿æ³¨å†Œå•ä½",
                sorted([v for v in df[reg_org_col].dropna().unique() if str(v).strip() != ""]) if reg_org_col else [],
                help="é€‰æ‹©è¿™äº›æ³¨å†Œå•ä½çš„ä¸“å®¶å°†è¢«å‰”é™¤")

        # åŸºäºæ¡ä»¶è¿‡æ»¤
        clone_filtered = df.copy()
        if major_cn in clone_filtered.columns and major_sel:
            clone_filtered = clone_filtered[clone_filtered[major_cn].isin(major_sel)]
        if title_cn in clone_filtered.columns and title_sel:
            clone_filtered = clone_filtered[clone_filtered[title_cn].isin(title_sel)]
        if gender_col and gender_sel != "å…¨éƒ¨":
            clone_filtered = clone_filtered[clone_filtered[gender_col] == gender_sel]
        if birth_col and age_range is not None:
            ages = compute_age_series(clone_filtered[birth_col])
            clone_filtered = clone_filtered[(ages >= age_range[0]) & (ages <= age_range[1])]
        if degree_col and degree_sel != "å…¨éƒ¨":
            clone_filtered = clone_filtered[clone_filtered[degree_col] == degree_sel]
        # å›é¿å•ä½å‰”é™¤
        if org_col and avoid_orgs:
            clone_filtered = clone_filtered[~clone_filtered[org_col].isin(avoid_orgs)]
        if reg_org_col and avoid_reg_orgs:
            clone_filtered = clone_filtered[~clone_filtered[reg_org_col].isin(avoid_reg_orgs)]

        st.caption(f"ç¬¦åˆæ¡ä»¶è®°å½•ï¼š{clone_filtered.shape[0]} äºº")

        # æ“ä½œæŒ‰é’®ï¼ˆæ›´è´´åˆéæŠ€æœ¯ç”¨æˆ·ï¼‰
        st.markdown("---")
        btn_col1, btn_col2 = st.columns([1, 1])
        do_draw = btn_col1.button("ğŸ¯ æŠ½å–", type="primary", use_container_width=True, key="clone_draw")
        do_print = btn_col2.button("ğŸ–¨ï¸ æ‰“å°åˆ—è¡¨", use_container_width=True, key="clone_print")

        selected = pd.DataFrame()
        if do_draw:
            selected = sample_rows(clone_filtered, int(num_people), seed=None)
            st.success(f"å·²æŠ½å– {selected.shape[0]} äººã€‚")
            # å±•ç¤ºä¸ä¸‹è½½ï¼ˆä½¿ç”¨åŸºæœ¬äº”å­—æ®µï¼Œå¦‚æœ‰å¯é€‰å­—æ®µåˆ™è¿½åŠ å±•ç¤ºï¼‰
            base_cols = [
                REQUIRED_FIELDS_CN["name"],
                major_cn if major_cn in selected.columns else None,
                REQUIRED_FIELDS_CN["phone"],
                title_cn if title_cn in selected.columns else None,
                REQUIRED_FIELDS_CN["email"],
            ]
            base_cols = [c for c in base_cols if c and c in selected.columns]
            show_cols = base_cols.copy()
            for opt_key in ["gender", "birth", "org", "position", "reg_org"]:
                col = optional_cols.get(opt_key)
                if col and col in selected.columns:
                    show_cols.append(col)
            st.dataframe(selected[show_cols] if show_cols else selected, use_container_width=True)

            # ä¸‹è½½
            csv_bytes = (selected[show_cols] if show_cols else selected).to_csv(index=False).encode("utf-8-sig")
            excel_bytes = to_excel_bytes(selected[show_cols] if show_cols else selected)
            st.download_button("ä¸‹è½½ CSV", data=csv_bytes, file_name="æŠ½å–ç»“æœ.csv", mime="text/csv")
            st.download_button("ä¸‹è½½ Excel", data=excel_bytes, file_name="æŠ½å–ç»“æœ.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

        # æ‰“å°ï¼ˆç”Ÿæˆç®€æ´HTMLå¹¶è§¦å‘æµè§ˆå™¨æ‰“å°ï¼‰
        if do_print:
            preview = clone_filtered.head(200)
            html_table = preview.to_html(index=False)
            st_html(
                f"""
                <div>
                  <style>
                    table {{border-collapse: collapse; width: 100%; font-size: 12px;}}
                    th, td {{border: 1px solid #999; padding: 6px;}}
                  </style>
                  <h3 style='margin:8px 0'>é¡¹ç›®åç§°ï¼š{proj_name or ''} ï½œ æ‹›æ ‡äººï¼š{owner_name or ''} ï½œ æ‹›æ ‡ç¼–å·ï¼š{bid_no or ''} ï½œ æŠ½å–æ—¶é—´ï¼š{draw_time or ''}</h3>
                  {html_table}
                  <script>window.print();</script>
                </div>
                """,
                height=520,
            )


if __name__ == "__main__":
    main()
